{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Determine if an nvidia GPU is available"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9cd057b9d5db7b3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T18:21:00.674206400Z",
     "start_time": "2024-02-05T18:21:00.643907600Z"
    }
   },
   "id": "4443f42022c13b8e",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on device: \", device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T18:21:00.693785100Z",
     "start_time": "2024-02-05T18:21:00.680571900Z"
    }
   },
   "id": "2abcc546d59e2b1b",
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load models"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f56141ae93ea8e9b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from types import MethodType"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T18:21:00.743879500Z",
     "start_time": "2024-02-05T18:21:00.705240600Z"
    }
   },
   "id": "a9e5e72c370d93be",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "mtcnn = MTCNN(keep_all=True, device=device)\n",
    "\n",
    "def detect_box(self, img, save_path=None):\n",
    "    # Detect faces\n",
    "    batch_boxes, batch_probs, batch_points = self.detect(img, landmarks=True)\n",
    "    # Select faces\n",
    "    if not self.keep_all:\n",
    "        batch_boxes, batch_probs, batch_points = self.select_boxes(\n",
    "            batch_boxes, batch_probs, batch_points, img, method=self.selection_method\n",
    "        )\n",
    "    # Extract faces\n",
    "    faces = self.extract(img, batch_boxes, save_path)\n",
    "    return batch_boxes, faces\n",
    "\n",
    "mtcnn.detect_box = MethodType(detect_box, mtcnn)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T18:21:01.527041300Z",
     "start_time": "2024-02-05T18:21:00.705240600Z"
    }
   },
   "id": "f6a3b5c7ada001b",
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get the saved faces"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c596542c2da719a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import os\n",
    "\n",
    "workers = 0 if os.name == 'nt' else 4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T18:21:01.543213700Z",
     "start_time": "2024-02-05T18:21:01.534685500Z"
    }
   },
   "id": "2c881d9abbd7eae3",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "dict_items([(0, 'Mayank'), (1, 'Seema'), (2, 'Vaibhav')])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.ImageFolder(\"./faces\")\n",
    "idx_to_class = {i:c for c, i in dataset.class_to_idx.items()}\n",
    "loader = DataLoader(dataset ,collate_fn=lambda x: x[0], num_workers=workers)\n",
    "idx_to_class.items()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T18:21:01.593925200Z",
     "start_time": "2024-02-05T18:21:01.534685500Z"
    }
   },
   "id": "fdac7c1c6fea371f",
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get encoded features of all saved images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1faef76fcd2feeae"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "aligned_faces = []\n",
    "labels = []\n",
    "\n",
    "for image, label in loader:\n",
    "    image_aligned = mtcnn(image)\n",
    "\n",
    "    if image_aligned is not None:\n",
    "        aligned_faces.append(image_aligned)\n",
    "        labels.append(label)\n",
    "\n",
    "aligned_faces = torch.cat(aligned_faces, dim=0).to(device)\n",
    "embeddings = resnet(aligned_faces).detach().cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T18:21:02.142819300Z",
     "start_time": "2024-02-05T18:21:01.563803600Z"
    }
   },
   "id": "118cd692c56fe157",
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classify image"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "357e879e74e3f943"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T18:21:02.146571100Z",
     "start_time": "2024-02-05T18:21:02.145556800Z"
    }
   },
   "id": "1128736422789b68",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def classify_face(image, threshold=0.7):\n",
    "    embedding = resnet(image.to(device)).detach().cpu().reshape(1, -1)\n",
    "\n",
    "    similarity = F.cosine_similarity(x1=embeddings, x2=embedding).reshape(-1)\n",
    "    max_index = similarity.argmax().item()\n",
    "\n",
    "    return labels[max_index] if similarity[max_index] > threshold else None"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T18:21:02.157352800Z",
     "start_time": "2024-02-05T18:21:02.146571100Z"
    }
   },
   "id": "239c2285885802bf",
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Live Detection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3a3f3a34df1a84e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def detect(cam=0, threshold=0.6):\n",
    "    vid = cv2.VideoCapture(cam)\n",
    "\n",
    "    while vid.grab():\n",
    "        _, img, = vid.retrieve()\n",
    "        batch_boxes, aligned_images = mtcnn.detect_box(img)\n",
    "\n",
    "        if aligned_images is not None:\n",
    "            for box, aligned in zip(batch_boxes, aligned_images):\n",
    "                aligned = torch.Tensor(aligned.unsqueeze(0))\n",
    "                x1, y1, x2, y2 = [int(x) for x in box]\n",
    "\n",
    "                idx = classify_face(image=aligned, threshold=threshold)\n",
    "                idx = idx_to_class[idx] if idx is not None else \"Unknown\"\n",
    "\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                cv2.putText(img, idx, (x1 + 5, y1 + 10), cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        cv2.imshow(\"Face Recognition\", img)\n",
    "        if cv2.waitKey(1) == ord(\"q\"):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T18:21:02.172883Z",
     "start_time": "2024-02-05T18:21:02.163880100Z"
    }
   },
   "id": "7d7692d59f49c438",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "detect(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T18:21:06.744973400Z",
     "start_time": "2024-02-05T18:21:02.173893800Z"
    }
   },
   "id": "be1998af73bc77f3",
   "execution_count": 46
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
